{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO04Ucnb3x8IBoj1lXaHe/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SridharanS2001/PIEL_model/blob/main/Codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANQAa9Lv6bss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model_Optimization**"
      ],
      "metadata": {
        "id": "l7fHPri56cKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEjy78sp6Wsg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "\n",
        "d = pd.read_csv('/content/Final data.csv')\n",
        "X = d.iloc[:, 0:11].values\n",
        "y = d.iloc[:, 11].values\n",
        "\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0),\n",
        "    'SVR': SVR(C=100, degree=2, epsilon=0.01, gamma='scale', kernel='rbf'),\n",
        "    'RandomForest': RandomForestRegressor(max_depth=15, n_estimators=100, max_features='sqrt'),\n",
        "    'DecisionTree': DecisionTreeRegressor(max_depth=15, min_samples_leaf=4),\n",
        "    'LightGBM': lgb.LGBMRegressor(learning_rate=0.1, n_estimators=100, max_depth=-1, subsample=0.8, colsample_bytree=0.8),\n",
        "    'Lasso': Lasso(alpha=0.0001),\n",
        "    'KNN': KNeighborsRegressor(n_neighbors=11, p=1, weights='distance')\n",
        "}\n",
        "\n",
        "\n",
        "def evaluate_ensemble(X, y, model_names, k=5):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    val_rmse_scores, train_rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_val = X[train_idx], X[test_idx]\n",
        "        y_train, y_val = y[train_idx], y[test_idx]\n",
        "\n",
        "        preds_train = np.zeros((len(y_train), len(model_names)))\n",
        "        preds_val = np.zeros((len(y_val), len(model_names)))\n",
        "\n",
        "        for i, name in enumerate(model_names):\n",
        "            model = models[name]\n",
        "            model.fit(X_train, y_train)\n",
        "            preds_train[:, i] = model.predict(X_train)\n",
        "            preds_val[:, i] = model.predict(X_val)\n",
        "\n",
        "        y_pred_train = preds_train.mean(axis=1)\n",
        "        y_pred_val = preds_val.mean(axis=1)\n",
        "\n",
        "        train_rmse_scores.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
        "        val_rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred_val)))\n",
        "        r2_scores.append(r2_score(y_val, y_pred_val))\n",
        "\n",
        "    return (np.mean(train_rmse_scores),\n",
        "            np.mean(val_rmse_scores),\n",
        "            np.mean(r2_scores))\n",
        "\n",
        "def find_best_ensemble(X, y, min_models=2, max_models=7):\n",
        "    results = []\n",
        "    keys = list(models.keys())\n",
        "\n",
        "    for r in range(min_models, min(max_models, len(keys)) + 1):\n",
        "        for combo in combinations(keys, r):\n",
        "            train_rmse, val_rmse, r2 = evaluate_ensemble(X, y, combo)\n",
        "            results.append({\n",
        "                'models': combo,\n",
        "                'val_rmse': val_rmse,\n",
        "                'train_rmse': train_rmse,\n",
        "                'r2': r2\n",
        "            })\n",
        "\n",
        "\n",
        "    val_rmse_max = max(r['val_rmse'] for r in results)\n",
        "    r2_max = max(r['r2'] for r in results)\n",
        "\n",
        "    for r in results:\n",
        "        norm_rmse = r['val_rmse'] / val_rmse_max\n",
        "        norm_r2 = 1 - r['r2'] / r2_max\n",
        "        r['score'] = norm_rmse + norm_r2\n",
        "\n",
        "    results_sorted = sorted(results, key=lambda x: x['score'])\n",
        "\n",
        "    return results_sorted\n",
        "\n",
        "\n",
        "all_results = find_best_ensemble(X, y)\n",
        "\n",
        "\n",
        "best = all_results[0]\n",
        "print(\" Best Model Combination:\", best['models'])\n",
        "print(f\"   Validation RMSE: {best['val_rmse']:.4f}\")\n",
        "print(f\"   Training RMSE: {best['train_rmse']:.4f}\")\n",
        "print(f\"   RÂ²: {best['r2']:.4f}\")\n",
        "print(f\"   Combined Score: {best['score']:.4f}\")\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(all_results)\n",
        "df_results['model_count'] = df_results['models'].apply(len)\n",
        "df_results['model_names'] = df_results['models'].apply(lambda x: ' + '.join(x))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(df_results['model_names'], df_results['val_rmse'], 'o-', color='red', label='Val RMSE')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Validation RMSE')\n",
        "plt.ylabel('RMSE')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(df_results['model_names'], df_results['r2'], 'o-', color='blue', label='RÂ²')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Validation RÂ²')\n",
        "plt.ylabel('RÂ² Score')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Top 5 Model Combinations Based on Score:\")\n",
        "display(df_results[['model_names', 'val_rmse', 'r2', 'score']].sort_values(by='score').head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ensemble optimized Model**"
      ],
      "metadata": {
        "id": "W2orxKjD6yp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "\n",
        "\n",
        "models = {\n",
        "\n",
        "    'RandomForest': RandomForestRegressor(max_depth=15, n_estimators=100, max_features='sqrt', random_state=42),\n",
        "    'DecisionTree': DecisionTreeRegressor(max_depth=15, min_samples_leaf=4, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(learning_rate=0.1, n_estimators=100, max_depth=-1, subsample=0.8, colsample_bytree=0.8, random_state=42),\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rmse_train_list = []\n",
        "r2_train_list = []\n",
        "rmse_test_list = []\n",
        "r2_test_list = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    train_preds = []\n",
        "    test_preds = []\n",
        "\n",
        "    print(f\"\\nðŸ“‚ Fold {fold}\")\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        train_pred = model.predict(X_train_scaled)\n",
        "        test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        train_preds.append(train_pred)\n",
        "        test_preds.append(test_pred)\n",
        "\n",
        "        print(f\"    {name} - Train RMSE: {np.sqrt(mean_squared_error(y_train, train_pred)):.4f}, RÂ²: {r2_score(y_train, train_pred):.4f}\")\n",
        "        print(f\"    {name} - Test  RMSE: {np.sqrt(mean_squared_error(y_test, test_pred)):.4f}, RÂ²: {r2_score(y_test, test_pred):.4f}\")\n",
        "\n",
        "    ensemble_train = np.mean(train_preds, axis=0)\n",
        "    ensemble_test = np.mean(test_preds, axis=0)\n",
        "\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, ensemble_train))\n",
        "    r2_train = r2_score(y_train, ensemble_train)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, ensemble_test))\n",
        "    r2_test = r2_score(y_test, ensemble_test)\n",
        "\n",
        "    rmse_train_list.append(rmse_train)\n",
        "    r2_train_list.append(r2_train)\n",
        "    rmse_test_list.append(rmse_test)\n",
        "    r2_test_list.append(r2_test)\n",
        "\n",
        "    print(f\" Ensemble - Train RMSE: {rmse_train:.4f}, RÂ²: {r2_train:.4f}\")\n",
        "    print(f\" Ensemble - Test  RMSE: {rmse_test:.4f}, RÂ²: {r2_test:.4f}\")\n",
        "\n",
        "\n",
        "print(\" Final Cross-Validation Results (Average of 5 folds):\")\n",
        "print(f\" Train RMSE: {np.mean(rmse_train_list):.4f}, RÂ²: {np.mean(r2_train_list):.4f}\")\n",
        "print(f\" Test  RMSE: {np.mean(rmse_test_list):.4f}, RÂ²: {np.mean(r2_test_list):.4f}\")\n"
      ],
      "metadata": {
        "id": "bh23ABDK6sJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Input_Parameter_calculation**"
      ],
      "metadata": {
        "id": "Ie8hXHFh7GnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import metallurgy as mg\n",
        "\n",
        "\n",
        "composition = {'Ti': 29.7 ,'Ni':50.3,'Ta': 4, 'Zr': 16}\n",
        "\n",
        "\n",
        "alloy_str = ''.join([f\"{elem}{amt}\" for elem, amt in composition.items()])\n",
        "alloy = mg.Alloy(alloy_str)\n",
        "\n",
        "\n",
        "electronegativity = {'Ni': 1.91, 'Ti': 1.54, 'Si': 1.9, 'Co': 1.88, 'Mo': 2.16, 'Fe': 7.87, 'V': 1.63,\n",
        "    'Cr': 1.66, 'Al': 1.61, 'Nb': 1.6, 'Mn': 1.55, 'Ta': 1.5, 'Cu': 1.9, 'Zr': 1.33, 'Hf': 1.3}\n",
        "density = {'Ni': 8.91,'Hf': 13.3, 'Ti': 4.5, 'Si': 2.32, 'Co': 8.86, 'Mo': 10.2, 'Fe': 7.87, 'V': 6,\n",
        "    'Cr': 7.15, 'Al': 2.7, 'Nb': 8.59, 'Mn': 7.3, 'Ta': 16.4, 'Cu': 8.9, 'Zr': 6.32}\n",
        "radius = {'Hf': 212, 'Ni': 163, 'Ti': 187, 'Si': 210, 'Co': 192, 'Mo': 209, 'Fe': 194, 'V': 179,\n",
        "    'Cr': 189, 'Al': 184, 'Nb': 207, 'Mn': 197, 'Ta': 217, 'Cu': 140, 'Zr': 186}\n",
        "atomic_weight = { 'Hf': 178.49, 'Ni': 58.69, 'Ti': 48.867, 'Si': 28.085, 'Co': 58.933, 'Mo': 95.95, 'Fe': 55.84, 'V': 50.94,\n",
        "    'Cr': 51.996, 'Al': 26.98, 'Nb': 92.90, 'Mn': 54.93, 'Ta': 180.94, 'Cu': 63.55, 'Zr': 91.22}\n",
        "ie = {'Hf': 6.825, 'Ni': 7.64, 'Ti': 6.828, 'Si': 8.152, 'Co': 7.881, 'Mo': 7.092, 'Fe': 7.902, 'V': 6.746,\n",
        "    'Cr': 6.767, 'Al': 5.986, 'Nb': 6.759, 'Mn': 7.434, 'Ta': 7.89, 'Cu': 7.726, 'Zr': 6.634}\n",
        "cp = {'Hf': 144, 'Ni': 445, 'Ti': 520, 'Si': 710, 'Co': 421, 'Mo': 251, 'Fe': 449, 'V': 489,\n",
        "    'Cr': 448, 'Al': 904, 'Nb': 265, 'Mn': 479, 'Ta': 140, 'Cu': 384.4, 'Zr': 278}\n",
        "E = {'Hf': 4, 'Ni': 10, 'Ti': 4, 'Si': 4, 'Co': 9, 'Mo': 6, 'Fe': 8, 'V': 5,\n",
        "    'Cr': 6, 'Al': 3, 'Nb': 5, 'Mn': 7, 'Ta': 5, 'Cu': 11, 'Zr': 4}\n",
        "\n",
        "\n",
        "def mean_electronegativity(comp):\n",
        "    total = sum(comp[e] for e in comp if e in electronegativity)\n",
        "    weighted_sum = sum(comp[e] * electronegativity[e] for e in comp if e in electronegativity)\n",
        "    return weighted_sum / total if total != 0 else 0\n",
        "\n",
        "def custom_dX(comp):\n",
        "    weighted_total = mean_electronegativity(comp)\n",
        "    terms = [\n",
        "        float(comp[e]) * ((weighted_total - electronegativity[e]) ** 2)\n",
        "        for e in comp if e in electronegativity\n",
        "    ]\n",
        "    return np.sqrt(sum(terms))\n",
        "\n",
        "def mean_ie(comp): return sum(float(comp[e]) * ie[e] for e in comp)/100\n",
        "def mean_E(comp): return sum(float(comp[e]) * E[e] for e in comp)/100\n",
        "def mean_mass(comp): return sum(float(comp[e]) * atomic_weight[e] for e in comp)/100\n",
        "def mean_density(comp): return sum(float(comp[e]) * density[e] for e in comp)/100\n",
        "\n",
        "def xmean_density(comp):\n",
        "    total = sum(comp[e] for e in comp if e in density)\n",
        "    weighted_sum = sum(comp[e] * density[e] for e in comp if e in density)\n",
        "    return weighted_sum / total if total != 0 else 0\n",
        "def custom_dd(comp):\n",
        "    weighted_total = xmean_density(comp)\n",
        "    terms = [\n",
        "        float(comp[e]) * ((weighted_total - density[e]) ** 2)\n",
        "        for e in comp if e in density\n",
        "    ]\n",
        "    return np.sqrt(sum(terms))\n",
        "\n",
        "def mean_radius(comp): return sum(float(comp[e]) * radius[e] for e in comp)/100\n",
        "def mean_cp(comp): return sum(float(comp[e]) * cp[e] for e in comp)/100\n",
        "\n",
        "\n",
        "def mie(comp):\n",
        "    total = sum(comp[e] for e in comp if e in density)\n",
        "    weighted_sum = sum(comp[e] * density[e] for e in comp if e in density)\n",
        "    return weighted_sum / total if total != 0 else 0\n",
        "def die(comp):\n",
        "    weighted_total = mie(comp)\n",
        "    terms = [\n",
        "        float(comp[e]) * ((weighted_total - ie[e]) ** 2)\n",
        "        for e in comp if e in ie\n",
        "    ]\n",
        "    return np.sqrt(sum(terms))\n",
        "\n",
        "def enthalpy(comp):\n",
        "    hmat = pd.read_csv('/content/Enthalpy_Mixing1_filled.csv', index_col=0)\n",
        "    elements = list(comp.keys())\n",
        "    h = 0\n",
        "    for i in range(len(elements)):\n",
        "        for j in range(i+1, len(elements)):\n",
        "            Ci = float(comp[elements[i]]) / 100\n",
        "            Cj = float(comp[elements[j]]) / 100\n",
        "            Hij = hmat.loc[elements[i], elements[j]]\n",
        "            h += 4 * Ci * Cj * Hij\n",
        "    return h\n",
        "\n",
        "print(\"Ideal Entropy (J/molÂ·K):\", mg.entropy.ideal_entropy(alloy))\n",
        "print(\"Mean Ionization Energy (eV):\", mean_ie(composition))\n",
        "print(\"Mean Atomic Mass (g/mol):\", mean_mass(composition))\n",
        "print(\"Mean Density (g/cmÂ³):\", mean_density(composition))\n",
        "print(\"Electronegativity Difference (dX):\", custom_dX(composition))\n",
        "print(\"Density Deviation:\", custom_dd(composition))\n",
        "print(\"Mean Atomic Radius (pm):\", mean_radius(composition))\n",
        "print(\"Mean Heat Capacity (J/kgÂ·K):\", mean_cp(composition))\n",
        "print(\"Mean Valence Electron Concentration (e/a):\", mean_E(composition))\n",
        "print(\"IE Deviation:\", die(composition))\n",
        "print(\"Enthalpy of Mixing (kJ/mol):\", enthalpy(composition))"
      ],
      "metadata": {
        "id": "9tabESiX7MXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prediction**"
      ],
      "metadata": {
        "id": "j4EQgM3w7WED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = pd.DataFrame([[1.1281769895955966,\n",
        "                            7.247875999999999,\n",
        "                            65.867369,\n",
        "                            7.48543,\n",
        "                            2.306661481448892,\n",
        "                            26.5781602356145,\n",
        "                            175.968,\n",
        "                            428.355,\n",
        "                            5.127588122499698,\n",
        "                            -38.78921088,\n",
        "                            0]])\n",
        "\n",
        "new_input_scaled = scaler.transform(new_input)\n",
        "\n",
        "\n",
        "new_preds = [model.predict(new_input_scaled)[0] for model in models.values()]\n",
        "\n",
        "ensemble_prediction = np.mean(new_preds)\n",
        "c = ensemble_prediction - 273\n",
        "\n",
        "print(\" Individual Model Predictions:\")\n",
        "for name, pred in zip(models.keys(), new_preds):\n",
        "    print(f\"    {name}: {pred:.4f}\")\n",
        "\n",
        "print(f\" Ensemble Prediction in K: {ensemble_prediction:.4f}\")\n",
        "print(f\" Ensemble Prediction in C: {c:.4f}\")"
      ],
      "metadata": {
        "id": "H_ZyZS0V7YHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SHAP plot**"
      ],
      "metadata": {
        "id": "0rLdBQDK7m4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer_rf = shap.Explainer(models['RandomForest'], X_train_scaled)\n",
        "explainer_dt = shap.Explainer(models['DecisionTree'], X_train_scaled)\n",
        "explainer_lgb = shap.Explainer(models['LightGBM'], X_train_scaled)\n",
        "\n",
        "shap_values_rf = explainer_rf(X_test_scaled)\n",
        "shap_values_dt = explainer_dt(X_test_scaled)\n",
        "shap_values_lgb = explainer_lgb(X_test_scaled)\n",
        "\n",
        "avg_shap_values = (shap_values_rf.values + shap_values_dt.values + shap_values_lgb.values) / 3\n",
        "\n",
        "shap_values_ensemble = shap.Explanation(\n",
        "    values=avg_shap_values,\n",
        "    base_values=np.mean([shap_values_rf.base_values, shap_values_dt.base_values, shap_values_lgb.base_values], axis=0),\n",
        "    data=X_test_scaled,\n",
        "    feature_names=df.columns[:11].tolist()\n",
        ")\n",
        "\n",
        "shap.plots.beeswarm(shap_values_ensemble, max_display=10)\n"
      ],
      "metadata": {
        "id": "Az9Uxrup7ibC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Correlation**"
      ],
      "metadata": {
        "id": "MLkl03Wg7vZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "os.makedirs(\"Ms_vs_Features_CSV\", exist_ok=True)\n",
        "\n",
        "\n",
        "X = df.iloc[:, :11].values\n",
        "y = df.iloc[:, 11].values\n",
        "feature_names = df.columns[:11]\n",
        "\n",
        "\n",
        "models = {\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'DecisionTree': DecisionTreeRegressor(max_depth=15, min_samples_leaf=4, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, subsample=0.8,\n",
        "                                   colsample_bytree=0.8, random_state=42),\n",
        "}\n",
        "\n",
        "predicted_features = []\n",
        "target_range = np.linspace(y.min(), y.max(), 100)\n",
        "\n",
        "for i in range(X.shape[1]):\n",
        "    predictions = []\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(y.reshape(-1, 1), X[:, i])\n",
        "        pred = model.predict(target_range.reshape(-1, 1))\n",
        "        predictions.append(pred)\n",
        "\n",
        "    ensemble_pred = np.mean(predictions, axis=0)\n",
        "    predicted_features.append(ensemble_pred)\n",
        "\n",
        "    df_out = pd.DataFrame({\n",
        "        'Ms_Temperature': target_range,\n",
        "        f'Ensemble_Predicted_{feature_names[i]}': ensemble_pred\n",
        "    })\n",
        "    csv_filename = f'Ms_vs_Features_CSV/Ms_vs_{feature_names[i]}.csv'\n",
        "    df_out.to_csv(csv_filename, index=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(target_range, ensemble_pred, label=f'Ensemble Predicted {feature_names[i]}', color='darkorange')\n",
        "    plt.xlabel('Ms Temperature')\n",
        "    plt.ylabel(f'{feature_names[i]}')\n",
        "    plt.title(f'Ms vs {feature_names[i]} (Ensemble Prediction)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kE-VzXVu7xdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA_based classification**"
      ],
      "metadata": {
        "id": "LUM-6NbX7_2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "df = pd.read_csv('/content/Final data.csv')\n",
        "X = df.iloc[:, :11].values\n",
        "y = df.iloc[:, 11].values\n",
        "\n",
        "\n",
        "bins = [0, 973, float('inf')]\n",
        "labels = [1, 2]\n",
        "df['Ms_Category'] = pd.cut(y, bins=bins, labels=labels, right=False)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_2D = pca.fit_transform(X_scaled)\n",
        "\n",
        "\n",
        "x_min, x_max = X_2D[:, 0].min() - 1, X_2D[:, 0].max() + 1\n",
        "y_min, y_max = X_2D[:, 1].min() - 1, X_2D[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_2D, df['Ms_Category'])\n",
        "\n",
        "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.4, cmap=\"coolwarm\")\n",
        "\n",
        "sns.scatterplot(x=X_2D[:, 0], y=X_2D[:, 1], hue=df['Ms_Category'], palette=\"coolwarm\", s=50, edgecolor='k')\n",
        "\n",
        "\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.title('Contour Plot of Ms Categories (2 classes)')\n",
        "plt.legend(title='Ms Category')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4-lEsmQj7-qC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}